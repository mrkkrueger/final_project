# Final Project - Recidivism
The goal of this project is to use machine learning to analyze a dataset to develop a model to predict recidivism rates. This is an important area of research as it can help influence policy decision making in the field of criminal justice. Understanding what makes someone more or less like to commit new crimes after release can help us create a more effective criminal justice system.

Data for this project came from the National Institute of Justice Recidivism Challenge (https://data.ojp.usdoj.gov/stories/s/daxx-hznc). The data looks at just under 26,000 individuals that were released from Georgia prisons to community supervison from January 1, 2013 - December 31, 2013. The dataset was loaded into a Pandas DataFrame from my GoogleDrive. Users may need to adjust this code to connect to their own drive (the CSV file is included in this repository in the folder NIJs Recidivism Challenge Full Dataset).

A bar chart was initially created to help visualize the different measures of recidivism (New arrest in the 1st year, 2nd year, 3rd year, and overall). This showed that a new arrest is most likely to happen in the first year, and the likelihood decreases with each passing year. It also showed that over half of those released from prison had a new arrest within three years.

To clean the data, the columns "ID" and "Training_Sample" were dropped. The ID number assigned to the individual would have no impact on recidivism, and I will be creating my own training data so the "Training_Sample" column is not needed. Several columns had no limits on the number of digits a variable could have. This lead to cases of large numbers of unique variables. Theses columns were adjusted to be rounded to either the tenth place or whole number to make understanding the data easier. It was also decided to remove all rows with null values. A significant amount of the null values came from the columns relating to drug testing. This is likely because if someone did not receive any drug tests, it would not make sense to put in a value (for example, the column Avg_Days_per_DrugTest records the average days between drug tests, if there were no drug tests, you can't put a value here). I decided to remove all rows with null values. It is important to note that this changes the data to more heavily reflect drug use. Dummy variables were then created.

The dataset has four columns that measure recidivism - Recidivism_Within_3years, Recidivism_Arrest_Year1, Recidivism_Arrest_Year2, and Recidivism_Arrest_Year3. New dataframes were created for each of these columns that dropped the other recidvism columns. Further, the data frames for Year1, Year2, and Year3 were set up to only contain data if were someone recidivated during that year or not at all.
Next the data was split into training and test data and scaled. Machine learning was initially done with RandomFOrestClassifier. A model was made for Recidivism_Within_3years, Recidivism_Arrest_Year1, Recidivism_Arrest_Year2, and Recidivism_Arrest_Year3. Random Forests did a fairly good job at predicting. The accuracy for the models ranged from .71 to .92. The most important features for these models were Percent_Days_Employed, Avg_Days_per_DrugTest, Supervision_Risk_Score_First, and Residence_PUMA, suggesting that these four variables should be looked at in future research and policy making.

A neural network was then done to see if it would produce similar results to the random forests. As a whole, the results were similar were slight changes in accuracy.

The question then remains if 90% accuracy is accurate enough. In my opinion, it is not. With roughly 5 million people in the US either in prison or under some form of community corrections, that leaves 500,000 people that this model would be inaccurate for. That can result in a large number of people either being overly supervised, making it more difficult to integrage back into the community, or a large number of people being undersupervised which could put the community at risk.
